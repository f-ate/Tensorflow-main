{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31651dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for cuda enabled laptop and desktop\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL #pillow to handle images\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\" #tgz = tar ball (just like zip file)\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78147322",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/home/aarav/.keras/datasets/flower_photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/home/aarav/.keras/datasets/flower_photos/tulips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d10181",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/home/aarav/.keras/datasets/flower_photos/tulips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/home/aarav/.keras/datasets/flower_photos/daisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91623619",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/home/aarav/.keras/datasets/flower_photos/daisy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f74c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/home/aarav/.keras/datasets/flower_photos/sunflowers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695711eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/home/aarav/.keras/datasets/flower_photos/dandelion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/home/aarav/.keras/datasets/flower_photos/roses'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4280fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from glob import glob   #to handle folder/Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses_count = len(list(data_dir.glob('roses/*.jpg')))\n",
    "print(roses_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef451a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[45]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rose = image.load_img('/home/aarav/.keras/datasets/flower_photos/roses/1645761726_2b1be95472.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d168056",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906292bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = image.load_img('/home/aarav/.keras/datasets/flower_photos/daisy/4318007511_e9f4311936_n.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412695a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b23ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "for fname in os.listdir('/home/aarav/.keras/datasets/flower_photos/tulips'):\n",
    "  print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "tul = load_img('/home/aarav/.keras/datasets/flower_photos/tulips/5674134129_2db5136cba.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805907c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "IMG_HIEGHT = 224\n",
    "IMG_WIDHT = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=45,\n",
    "                                    width_shift_range=.15,\n",
    "                                    height_shift_range=.15,\n",
    "                                    horizontal_flip=True,\n",
    "                                    zoom_range=0.5,\n",
    "                                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
    "                                                    directory=data_dir,\n",
    "                                                    shuffle=True,\n",
    "                                                    target_size=(IMG_HIEGHT,IMG_HIEGHT),\n",
    "                                                    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdea67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790df8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255,\n",
    "                                  validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc99b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                directory=data_dir,\n",
    "                                                target_size=(IMG_HIEGHT,IMG_WIDHT),\n",
    "                                                subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6729c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,MaxPooling2D,Dropout\n",
    "model = Sequential([\n",
    "    Conv2D(16,3,padding='same',activation='relu',input_shape=(IMG_HIEGHT,IMG_WIDHT,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(32,3,padding='same',activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(64,3,padding='same',activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(5,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc846af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1bfede",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data_gen,validation_data=val_data_gen,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93202000",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(epochs)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range,acc,label='Training Accuracy')\n",
    "plt.plot(epochs_range,val_acc,label='Val Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range,loss,label='Training Loss')\n",
    "plt.plot(epochs_range,val_loss,label='Val LOss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'flowermodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b66a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = load_img('/home/aarav/.keras/datasets/flower_photos/roses/1540738662_7b4152e344_m.jpg',target_size=(IMG_HIEGHT,IMG_WIDHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde55fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = img_to_array(image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276195df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_img.reshape(1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461df689",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b583eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip'\n",
    "# filename = 'horse-or-human.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a9874c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
